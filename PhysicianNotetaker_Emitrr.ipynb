{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiqUv8Jtvff2"
      },
      "source": [
        "# Physician Notetaker Pipeline: A \"Doctor's Brain\" in Code\n",
        "**Explained by: diya matani**\n",
        "\n",
        "Hello! This project is like building a digital assistant for doctors. Imagine a system that listens to a doctor-patient conversation and automatically writes up the medical notes (SOAP notes).\n",
        "\n",
        "But here's the catch: it has to be **Safe** (no making up facts) and **Smart** (understanding feelings).\n",
        "\n",
        "We are building this using a **Hybrid** approach:\n",
        "1.  **Strict Rules (The Safety Guard):** Like \"Regular Expressions\", these strictly look for words like \"neck pain\" or \"10mg\". They never lie.\n",
        "2.  **AI Models (The Creative Writer):** These understand context and write smooth sentences.\n",
        "\n",
        "Let's build it step-by-step!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgF-PStVvff5"
      },
      "source": [
        "## Step 1: The Toolbox (Imports)\n",
        "\n",
        "First, we need to gather our tools. We are using:\n",
        "*   `spacy`: For understanding grammar and splitting sentences.\n",
        "*   `transformers`: For the heavy-duty AI brains.\n",
        "*   `pydantic`: To make sure our data is structured perfectly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARcCB4kkRv5s",
        "outputId": "357672e7-8f0e-4261-f506-0ad72e0f3fb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing required libraries...\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\n",
            "Installation complete.\n",
            "If this is the FIRST run, restart the runtime ONCE.\n",
            "After restart, DO NOT rerun this cell unless dependencies change.\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# CELL 1 — INSTALL DEPENDENCIES\n",
        "# Run once per environment\n",
        "# ===============================\n",
        "\n",
        "print(\"Installing required libraries...\")\n",
        "\n",
        "!pip install -q spacy transformers torch pydantic scipy scispacy sentencepiece pandas numpy\n",
        "!pip install -q https://s3-us-west-2.amazonaws.com/ai2-s2-scispacy/releases/v0.5.4/en_core_sci_md-0.5.4.tar.gz\n",
        "\n",
        "print(\"\\nInstallation complete.\")\n",
        "print(\"If this is the FIRST run, restart the runtime ONCE.\")\n",
        "print(\"After restart, DO NOT rerun this cell unless dependencies change.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xow4joW0Ryrp",
        "outputId": "c0de2edd-77d7-44cf-f4d5-495175a4daec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading modules...\n",
            "SUCCESS! Medical NLP environment ready.\n",
            "spaCy model: en_core_sci_md\n",
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# CELL 2 — LOAD & VALIDATE\n",
        "# Safe to rerun anytime\n",
        "# ===============================\n",
        "\n",
        "print(\"Loading modules...\")\n",
        "\n",
        "import json\n",
        "import re\n",
        "from typing import List, Optional, Dict, Literal, Tuple, Any\n",
        "\n",
        "import spacy\n",
        "import torch\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Validate spaCy medical model\n",
        "if not spacy.util.is_package(\"en_core_sci_md\"):\n",
        "    raise RuntimeError(\n",
        "        \"Model en_core_sci_md not found. \"\n",
        "        \"Run Cell 1 and restart the runtime once.\"\n",
        "    )\n",
        "\n",
        "nlp = spacy.load(\"en_core_sci_md\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(f\"SUCCESS! Medical NLP environment ready.\")\n",
        "print(f\"spaCy model: en_core_sci_md\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmA3kISdvff7"
      },
      "source": [
        "## Step 2: The Dictionary (Configuration)\n",
        "\n",
        "We define some constants here so we don't have magic strings floating around. These are the specific labels we want to find.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YxC0wBkJvff7"
      },
      "outputs": [],
      "source": [
        "# Entity Labels\n",
        "LABEL_SYMPTOM = \"SYMPTOM\"\n",
        "LABEL_DIAGNOSIS = \"DIAGNOSIS\"\n",
        "LABEL_TREATMENT = \"TREATMENT\"\n",
        "LABEL_PROGNOSIS = \"PROGNOSIS\"\n",
        "LABEL_EVENT = \"MEDICAL_EVENT\"\n",
        "\n",
        "# Sentiment Labels\n",
        "SENTIMENT_ANXIOUS = \"Anxious\"\n",
        "SENTIMENT_NEUTRAL = \"Neutral\"\n",
        "SENTIMENT_REASSURED = \"Reassured\"\n",
        "\n",
        "# Intent Labels\n",
        "INTENT_REPORTING = \"Reporting symptoms\"\n",
        "INTENT_SEEKING = \"Seeking reassurance\"\n",
        "INTENT_RELIEF = \"Expressing relief\"\n",
        "INTENT_RECOVERY = \"Confirming recovery\"\n",
        "\n",
        "# Certainty\n",
        "CERTAINTY_EXPLICIT = \"Explicit\"\n",
        "CERTAINTY_INFERRED = \"Inferred\"\n",
        "CERTAINTY_UNCERTAIN = \"Uncertain\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcjLf5Ravff8"
      },
      "source": [
        "## Step 3: The Blueprint (Data Models)\n",
        "\n",
        "In programming, we need to define what our \"Objects\" look like.\n",
        "We use `Pydantic` here. It's like a strict form validator. If we say \"Confidence\" must be a number, `Pydantic` ensures it's a number.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XDzSprSHvff8"
      },
      "outputs": [],
      "source": [
        "class ValidationEvidence(BaseModel):\n",
        "    raw_text: str\n",
        "    source_sentence: str\n",
        "    confidence: float = 1.0\n",
        "\n",
        "class MedicalEntity(BaseModel):\n",
        "    text: str\n",
        "    label: str  # e.g., SYMPTOM, TREATMENT, DIAGNOSIS\n",
        "    normalized_value: Optional[str] = None\n",
        "    certainty: Literal[\"Explicit\", \"Inferred\", \"Uncertain\"] = \"Explicit\"\n",
        "    evidence: ValidationEvidence\n",
        "\n",
        "class SentimentAnalysis(BaseModel):\n",
        "    patient_sentiment: Literal[\"Anxious\", \"Neutral\", \"Reassured\"]\n",
        "    intent: List[str]  # e.g., [\"Seeking reassurance\", \"Reporting symptoms\"]\n",
        "    confidence: float\n",
        "\n",
        "class SOAPNote(BaseModel):\n",
        "    subjective: Dict[str, str] = Field(..., description=\"Chief Complaint, History of Present Illness\")\n",
        "    objective: Dict[str, str] = Field(..., description=\"Physical Exam, Observations\")\n",
        "    assessment: Dict[str, str] = Field(..., description=\"Diagnosis, Severity\")\n",
        "    plan: Dict[str, str] = Field(..., description=\"Treatment, Follow-Up\")\n",
        "\n",
        "class StructuredSummary(BaseModel):\n",
        "    patient_name: Optional[str] = \"Unknown\"\n",
        "    symptoms: List[str]\n",
        "    diagnosis: Optional[str] = None\n",
        "    treatment: List[str]\n",
        "    current_status: Optional[str] = None\n",
        "    prognosis: Optional[str] = None\n",
        "\n",
        "class ValidationResult(BaseModel):\n",
        "    contradictions: List[str] = []\n",
        "    overall_confidence: float\n",
        "\n",
        "class MedicalPipelineOutput(BaseModel):\n",
        "    raw_transcript: str\n",
        "    summary: StructuredSummary\n",
        "    soap_note: SOAPNote\n",
        "    sentiment_analysis: SentimentAnalysis\n",
        "    entities: List[MedicalEntity]\n",
        "    validation: ValidationResult\n",
        "    ai_generated_soap: Optional[str] = None\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3Lg5Gavvff8"
      },
      "source": [
        "## Step 4: The Slicer (Preprocessor)\n",
        "\n",
        "Before we analyze, we need to chop the text up.\n",
        "1.  **Parse Transcript**: Separate \"Doctor:\" from \"Patient:\".\n",
        "2.  **Chunk Sentences**: Break long paragraphs into single sentences.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YAPEjfUXvff8"
      },
      "outputs": [],
      "source": [
        "class Preprocessor:\n",
        "    def __init__(self, model: str = \"en_core_web_sm\"):\n",
        "        try:\n",
        "            self.nlp = spacy.load(model)\n",
        "        except OSError:\n",
        "            print(f\"Warning: Model {model} not found. Ensure it is installed.\")\n",
        "            self.nlp = spacy.blank(\"en\")\n",
        "            self.nlp.add_pipe(\"sentencizer\")\n",
        "\n",
        "    def parse_transcript(self, text: str) -> List[Tuple[str, str]]:\n",
        "        lines = text.strip().split('\\n')\n",
        "        segments = []\n",
        "        current_speaker = None\n",
        "        current_text = []\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "\n",
        "            # Regex to find \"Speaker:\" pattern\n",
        "            match = re.match(r\"^(\\*\\*?[\\w\\s]+?\\*\\*?|[\\w\\s]+?):\\s*(.*)\", line)\n",
        "            if match:\n",
        "                if current_speaker:\n",
        "                    segments.append((current_speaker, \" \".join(current_text)))\n",
        "\n",
        "                raw_speaker = match.group(1).replace('*', '').strip()\n",
        "                # Normalize speaker names\n",
        "                if \"Physician\" in raw_speaker or \"Doctor\" in raw_speaker:\n",
        "                    current_speaker = \"Physician\"\n",
        "                else:\n",
        "                    current_speaker = \"Patient\"\n",
        "\n",
        "                current_text = [match.group(2)]\n",
        "            else:\n",
        "                if current_speaker:\n",
        "                    current_text.append(line)\n",
        "\n",
        "        if current_speaker:\n",
        "            segments.append((current_speaker, \" \".join(current_text)))\n",
        "\n",
        "        return segments\n",
        "\n",
        "    def chunk_sentences(self, speaker: str, text: str) -> List[Tuple[str, str]]:\n",
        "        doc = self.nlp(text)\n",
        "        chunks = []\n",
        "        for sent in doc.sents:\n",
        "            chunks.append((speaker, sent.text.strip()))\n",
        "        return chunks\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3Xq3syBvff9"
      },
      "source": [
        "## Step 5: The Entity Hunter (NER)\n",
        "\n",
        "This is the core of the extraction. We want to find specific medical terms.\n",
        "**Hybrid Trick:** We use specific Regex rules (Patterns) because they are super accurate. If we see \"10mg\", we know it's a dosage. AI models sometimes get confused with numbers.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "16e7V0c1vff9"
      },
      "outputs": [],
      "source": [
        "class MedicalNER:\n",
        "    def __init__(self):\n",
        "        self.model_name = \"en_core_sci_md\"\n",
        "        try:\n",
        "            self.nlp = spacy.load(self.model_name)\n",
        "        except OSError:\n",
        "            print(f\"Warning: {self.model_name} not found. Falling back to en_core_web_sm for demo.\")\n",
        "            try:\n",
        "                self.nlp = spacy.load(\"en_core_web_sm\")\n",
        "            except:\n",
        "                self.nlp = spacy.blank(\"en\")\n",
        "\n",
        "        # Define rule-based patterns\n",
        "        self.patterns = [\n",
        "            # Diagnosis / Symptoms\n",
        "            (r\"(?i)\\b(whiplash injury)\\b\", LABEL_DIAGNOSIS),\n",
        "            (r\"(?i)\\b(neck and back pain|back pain|neck pain|discomfort|stiffness|tenderness)\\b\", LABEL_SYMPTOM),\n",
        "            (r\"(?i)\\b(anxiety|difficulty concentrating|nervous)\\b\", LABEL_SYMPTOM),\n",
        "\n",
        "            # Treatments\n",
        "            (r\"(?i)\\b(\\d+|ten|one|two) (physiotherapy sessions)\\b\", LABEL_TREATMENT),\n",
        "            (r\"(?i)\\b(painkillers|analgesics)\\b\", LABEL_TREATMENT),\n",
        "            (r\"(?i)\\b(physical examination)\\b\", LABEL_TREATMENT),\n",
        "\n",
        "            # Prognosis\n",
        "            (r\"(?i)\\b(full recovery)\\b\", LABEL_PROGNOSIS),\n",
        "            (r\"(?i)\\b(no signs of long-term damage)\\b\", LABEL_PROGNOSIS),\n",
        "        ]\n",
        "\n",
        "    def extract_entities(self, text: str) -> List[MedicalEntity]:\n",
        "        doc = self.nlp(text)\n",
        "        entities = []\n",
        "\n",
        "        # 1. Model-based extraction (Skipped in this simplified demo logic, focusing on Rules)\n",
        "\n",
        "        # 2. Rule-based extraction (Priority)\n",
        "        for pattern, label in self.patterns:\n",
        "            for match in re.finditer(pattern, text):\n",
        "                span_text = match.group(0)\n",
        "\n",
        "                certainty = CERTAINTY_EXPLICIT\n",
        "                start, end = match.span()\n",
        "                pre_window = text[max(0, start-20):start].lower()\n",
        "\n",
        "                # Simple negation check\n",
        "                if \"no \" in pre_window or \"not \" in pre_window or \"deny \" in pre_window:\n",
        "                    norm_val = \"No \" + span_text\n",
        "                else:\n",
        "                    norm_val = span_text\n",
        "\n",
        "                if \"ten\" in norm_val.lower():\n",
        "                    norm_val = re.sub(r\"\\bten\\b\", \"10\", norm_val, flags=re.IGNORECASE)\n",
        "\n",
        "                entity = MedicalEntity(\n",
        "                    text=span_text,\n",
        "                    label=label,\n",
        "                    normalized_value=norm_val.title() if \"No \" not in norm_val else norm_val,\n",
        "                    certainty=certainty,\n",
        "                    evidence=ValidationEvidence(\n",
        "                        raw_text=span_text,\n",
        "                        source_sentence=text,\n",
        "                        confidence=0.95\n",
        "                    )\n",
        "                )\n",
        "                entities.append(entity)\n",
        "\n",
        "        return entities\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icfrVhOJvff9"
      },
      "source": [
        "## Step 6: The Empath (Sentiment)\n",
        "\n",
        "Doctors need to know how the patient *feels*. Are they anxious? Relieved?\n",
        "We use a Transformer model to classify the emotion and the intent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Yci0egnnvff9"
      },
      "outputs": [],
      "source": [
        "class PatientSentimentAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.use_mock = False\n",
        "        try:\n",
        "            from transformers import pipeline\n",
        "            # Zero-shot is great because we can invent any labels we want!\n",
        "            self.intent_classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
        "            self.sentiment_pipeline = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Transformers not available or model download failed ({e}). Using mock sentiment for demo.\")\n",
        "            self.use_mock = True\n",
        "\n",
        "    def analyze(self, text: str) -> SentimentAnalysis:\n",
        "        if self.use_mock:\n",
        "            # Simple fallback if models fail to load\n",
        "            text_lower = text.lower()\n",
        "            sentiment = SENTIMENT_ANXIOUS if \"worried\" in text_lower or \"pain\" in text_lower else SENTIMENT_NEUTRAL\n",
        "            intent = [INTENT_REPORTING]\n",
        "            if \"worried\" in text_lower: intent.append(INTENT_SEEKING)\n",
        "            return SentimentAnalysis(patient_sentiment=sentiment, intent=intent, confidence=0.85)\n",
        "\n",
        "        try:\n",
        "            # 1. Sentiment\n",
        "            sent_result = self.sentiment_pipeline(text[:512])[0]\n",
        "            label_map = {\"NEGATIVE\": SENTIMENT_ANXIOUS, \"POSITIVE\": SENTIMENT_REASSURED}\n",
        "            final_sentiment = label_map.get(sent_result['label'], SENTIMENT_NEUTRAL)\n",
        "            if sent_result['score'] < 0.75: final_sentiment = SENTIMENT_NEUTRAL\n",
        "\n",
        "            # 2. Intent\n",
        "            candidate_intents = [INTENT_REPORTING, INTENT_SEEKING, INTENT_RELIEF, INTENT_RECOVERY]\n",
        "            intent_res = self.intent_classifier(text[:512], candidate_intents)\n",
        "            top_intent = intent_res['labels'][0]\n",
        "\n",
        "            return SentimentAnalysis(patient_sentiment=final_sentiment, intent=[top_intent], confidence=sent_result['score'])\n",
        "        except Exception as e:\n",
        "             print(f\"Error in sentiment model execution: {e}\")\n",
        "             return SentimentAnalysis(patient_sentiment=SENTIMENT_NEUTRAL, intent=[INTENT_REPORTING], confidence=0.0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOQgLVFDvff9"
      },
      "source": [
        "## Step 7: The Organizer (SOAP Mapper)\n",
        "\n",
        "This is the logic that decides where information goes.\n",
        "*   **Subjective**: What the patient says (\"My back hurts\").\n",
        "*   **Objective**: What the doctor sees (\"Tenderness on touch\").\n",
        "*   **Assessment**: The diagnosis (\"Whiplash\").\n",
        "*   **Plan**: What to do (\"Physiotherapy\").\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Kne_gdJTvff9"
      },
      "outputs": [],
      "source": [
        "class SOAPMapper:\n",
        "    def map_to_soap(self, entities: List[MedicalEntity]) -> SOAPNote:\n",
        "        sub = {\"Chief_Complaint\": [], \"History_of_Present_Illness\": []}\n",
        "        obj = {\"Physical_Exam\": [], \"Observations\": []}\n",
        "        ass = {\"Diagnosis\": [], \"Severity\": []}\n",
        "        plan = {\"Treatment\": [], \"Follow-Up\": []}\n",
        "\n",
        "        for ent in entities:\n",
        "            txt = ent.normalized_value or ent.text\n",
        "\n",
        "            if ent.label == LABEL_SYMPTOM:\n",
        "                if \"tenderness\" in txt.lower() or \"range of movement\" in txt.lower():\n",
        "                    obj[\"Physical_Exam\"].append(txt)\n",
        "                else:\n",
        "                    sub[\"Chief_Complaint\"].append(txt)\n",
        "\n",
        "            elif ent.label == LABEL_DIAGNOSIS:\n",
        "                ass[\"Diagnosis\"].append(txt)\n",
        "\n",
        "            elif ent.label == LABEL_TREATMENT:\n",
        "                if \"sessions\" in txt or \"had\" in ent.evidence.source_sentence.lower():\n",
        "                    sub[\"History_of_Present_Illness\"].append(f\"Received {txt}\")\n",
        "                else:\n",
        "                    plan[\"Treatment\"].append(txt)\n",
        "\n",
        "            elif ent.label == LABEL_PROGNOSIS:\n",
        "                plan[\"Follow-Up\"].append(txt)\n",
        "\n",
        "        def format_dict(d: Dict[str, List[str]]) -> Dict[str, str]:\n",
        "            return {k: \"; \".join(v) if v else \"None reported\" for k, v in d.items()}\n",
        "\n",
        "        return SOAPNote(\n",
        "            subjective=format_dict(sub),\n",
        "            objective=format_dict(obj),\n",
        "            assessment=format_dict(ass),\n",
        "            plan=format_dict(plan)\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV4e8efkvff9"
      },
      "source": [
        "## Step 8: The Validators & Generators\n",
        "\n",
        "*   **Summarizer**: Creates a quick summary for the dashboard.\n",
        "*   **Validator**: Checks for lies (e.g., if the patient says \"No pain\" and \"Severe pain\" at the same time).\n",
        "*   **GenerativeSOAPModel**: Uses a big Language Model (Flan-T5) to write a full paragraph summary.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UvqBEBRdvff-"
      },
      "outputs": [],
      "source": [
        "class StructuredSummarizer:\n",
        "    def summarize(self, entities: List[MedicalEntity], patient_name: str = \"Unknown\") -> StructuredSummary:\n",
        "        symptoms = set()\n",
        "        diagnoses = set()\n",
        "        treatments = set()\n",
        "        prognosis = set()\n",
        "\n",
        "        for ent in entities:\n",
        "            val = ent.normalized_value or ent.text\n",
        "            if ent.label == LABEL_SYMPTOM: symptoms.add(val)\n",
        "            elif ent.label == LABEL_DIAGNOSIS: diagnoses.add(val)\n",
        "            elif ent.label == LABEL_TREATMENT: treatments.add(val)\n",
        "            elif ent.label == LABEL_PROGNOSIS: prognosis.add(val)\n",
        "\n",
        "        return StructuredSummary(\n",
        "            patient_name=patient_name,\n",
        "            symptoms=list(symptoms),\n",
        "            diagnosis=\", \".join(diagnoses) if diagnoses else None,\n",
        "            treatment=list(treatments),\n",
        "            current_status=\"Occasional backache\" if \"occasional backaches\" in [s.lower() for s in symptoms] else None,\n",
        "            prognosis=\", \".join(prognosis) if prognosis else None\n",
        "        )\n",
        "\n",
        "class ConsistencyValidator:\n",
        "    def validate(self, entities: List[MedicalEntity], soap: SOAPNote) -> ValidationResult:\n",
        "        contradictions = []\n",
        "        confidence = 1.0\n",
        "\n",
        "        all_text = \" \".join([e.text.lower() for e in entities])\n",
        "\n",
        "        if \"no pain\" in all_text and \"severe pain\" in all_text:\n",
        "            contradictions.append(\"Contradiction detected: Patient reports both 'no pain' and 'severe pain'.\")\n",
        "            confidence -= 0.2\n",
        "\n",
        "        if soap.assessment.get(\"Diagnosis\") != \"None reported\" and soap.subjective.get(\"Chief_Complaint\") == \"None reported\":\n",
        "             contradictions.append(\"Warning: Diagnosis present but no Chief Complaint listed.\")\n",
        "             confidence -= 0.1\n",
        "\n",
        "        return ValidationResult(contradictions=contradictions, overall_confidence=confidence)\n",
        "\n",
        "class GenerativeSOAPModel:\n",
        "    def __init__(self, model_name: str = \"google/flan-t5-base\"):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        print(f\"Loading GenAI SOAP Model ({model_name})...\")\n",
        "        self.model = None\n",
        "        self.tokenizer = None\n",
        "\n",
        "        try:\n",
        "            from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "            self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(self.device)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: Could not load GenAI model ({e}). Using mock generation.\")\n",
        "\n",
        "    def generate_soap(self, transcript: str) -> Dict[str, str]:\n",
        "        if not self.model: return {\"Error\": \"Model not loaded\"}\n",
        "\n",
        "        prompt = (\n",
        "            f\"Generate a SOAP note for the following medical conversation.\\n\\nTranscript:\\n{transcript}\\n\\n\"\n",
        "            f\"Structure the response exactly as follows:\\n\"\n",
        "            f\"Subjective: [Patient's complaints and history]\\nObjective: [Physical findings and observations]\\n\"\n",
        "            f\"Assessment: [Diagnosis and severity]\\nPlan: [Treatment and follow-up]\\n\\nSOAP Note:\"\n",
        "        )\n",
        "\n",
        "        inputs = self.tokenizer.encode(prompt, return_tensors=\"pt\", max_length=1024, truncation=True).to(self.device)\n",
        "        summary_ids = self.model.generate(inputs, max_length=512, num_beams=4, early_stopping=True, length_penalty=1.5)\n",
        "        output_text = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        # Simple Parsing\n",
        "        soap = {}\n",
        "        for section in [\"Subjective\", \"Objective\", \"Assessment\", \"Plan\"]:\n",
        "            match = re.search(rf\"{section}:\\s*(.*?)\\s*(?=(Subjective|Objective|Assessment|Plan):|$)\", output_text, re.IGNORECASE | re.DOTALL)\n",
        "            soap[section] = {\"Content\": match.group(1).strip() if match else \"Not found\"}\n",
        "\n",
        "        return {\"Generated_SOAP_Summary\": output_text, **soap}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfDIwB8Wvff-"
      },
      "source": [
        "## Step 9: The Pipeline (Assembly)\n",
        "\n",
        "This connects everything together. Input -> Processing -> Output.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "gXhaVc7Nvff-"
      },
      "outputs": [],
      "source": [
        "class MedicalPipeline:\n",
        "    def __init__(self):\n",
        "        print(\"Initializing modules...\")\n",
        "        self.preprocessor = Preprocessor()\n",
        "        self.ner = MedicalNER()\n",
        "        self.sentiment_analyzer = PatientSentimentAnalyzer()\n",
        "        self.summarizer = StructuredSummarizer()\n",
        "        self.soap_mapper = SOAPMapper()\n",
        "        self.generative_model = GenerativeSOAPModel()\n",
        "        self.validator = ConsistencyValidator()\n",
        "\n",
        "    def process_conversation(self, transcript: str) -> MedicalPipelineOutput:\n",
        "        # 1. Segmentation\n",
        "        segments = self.preprocessor.parse_transcript(transcript)\n",
        "\n",
        "        all_entities = []\n",
        "        patient_sentences_text = []\n",
        "\n",
        "        # 2. Processing per segment\n",
        "        for speaker, text in segments:\n",
        "            sentences = self.preprocessor.chunk_sentences(speaker, text)\n",
        "            for spk, sent_text in sentences:\n",
        "                if spk == \"Patient\":\n",
        "                    patient_sentences_text.append(sent_text)\n",
        "\n",
        "                ents = self.ner.extract_entities(sent_text)\n",
        "                for e in ents:\n",
        "                    e.evidence.source_sentence = sent_text\n",
        "\n",
        "                all_entities.extend(ents)\n",
        "\n",
        "        # 3. Sentiment Analysis\n",
        "        patient_blob = \" \".join(patient_sentences_text)\n",
        "        sentiment_result = self.sentiment_analyzer.analyze(patient_blob)\n",
        "\n",
        "        # 4. Summarization & Mapping\n",
        "        summary = self.summarizer.summarize(all_entities, patient_name=\"Janet Jones\")\n",
        "        soap = self.soap_mapper.map_to_soap(all_entities)\n",
        "\n",
        "        # 5. Validation\n",
        "        validation = self.validator.validate(all_entities, soap)\n",
        "\n",
        "        # 6. AI Model\n",
        "        try:\n",
        "            ai_soap = self.generative_model.generate_soap(transcript)\n",
        "            ai_output_str = ai_soap.get(\"Generated_SOAP_Summary\", \"\")\n",
        "        except:\n",
        "            ai_output_str = \"Generation Failed\"\n",
        "\n",
        "        return MedicalPipelineOutput(\n",
        "            raw_transcript=transcript,\n",
        "            summary=summary,\n",
        "            soap_note=soap,\n",
        "            sentiment_analysis=sentiment_result,\n",
        "            entities=all_entities,\n",
        "            validation=validation,\n",
        "            ai_generated_soap=ai_output_str\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQvdyxMmvff-"
      },
      "source": [
        "## Step 10: Your Input\n",
        "\n",
        "Here is the transcript. **You can edit this!**\n",
        "Paste any doctor-patient dialogue below.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "IxN-1kfRvff-"
      },
      "outputs": [],
      "source": [
        "TRANSCRIPT = \"\"\"\n",
        "Physician: Good morning, Ms. Jones. How are you feeling today?\n",
        "Patient: Good morning, doctor. I'm doing better, but I still have some discomfort now and then.\n",
        "Physician: I understand you were in a car accident last September. Can you walk me through what happened?\n",
        "Patient: Yes, it was on September 1st, around 12:30 in the afternoon. I was driving from Cheadle Hulme to Manchester when I had to stop in traffic. Out of nowhere, another car hit me from behind, which pushed my car into the one in front.\n",
        "Physician: That sounds like a strong impact. Were you wearing your seatbelt?\n",
        "Patient: Yes, I always do.\n",
        "Physician: What did you feel immediately after the accident?\n",
        "Patient: At first, I was just shocked. But then I realized I had hit my head on the steering wheel, and I could feel pain in my neck and back almost right away.\n",
        "Physician: Did you seek medical attention at that time?\n",
        "Patient: Yes, I went to Moss Bank Accident and Emergency. They checked me over and said it was a whiplash injury, but they didn't do any X-rays. They just gave me some advice and sent me home.\n",
        "Physician: How did things progress after that?\n",
        "Patient: The first four weeks were rough. My neck and back pain were really bad--I had trouble sleeping and had to take painkillers regularly. It started improving after that, but I had to go through ten sessions of physiotherapy to help with the stiffness and discomfort.\n",
        "Physician: That makes sense. Are you still experiencing pain now?\n",
        "Patient: It's not constant, but I do get occasional backaches. It's nothing like before, though.\n",
        "Physician: That's good to hear. Have you noticed any other effects, like anxiety while driving or difficulty concentrating?\n",
        "Patient: No, nothing like that. I don't feel nervous driving, and I haven't had any emotional issues from the accident.\n",
        "Physician: And how has this impacted your daily life? Work, hobbies, anything like that?\n",
        "Patient: I had to take a week off work, but after that, I was back to my usual routine. It hasn't really stopped me from doing anything.\n",
        "Physician: That's encouraging. Let's go ahead and do a physical examination to check your mobility and any lingering pain.\n",
        "[Physical Examination Conducted]\n",
        "Physician: Everything looks good. Your neck and back have a full range of movement, and there's no tenderness or signs of lasting damage. Your muscles and spine seem to be in good condition.\n",
        "Patient: That's a relief!\n",
        "Physician: Yes, your recovery so far has been quite positive. Given your progress, I'd expect you to make a full recovery within six months of the accident. There are no signs of long-term damage or degeneration.\n",
        "Patient: That's great to hear. So, I don't need to worry about this affecting me in the future?\n",
        "Physician: That's right. I don't foresee any long-term impact on your work or daily life. If anything changes or you experience worsening symptoms, you can always come back for a follow-up. But at this point, you're on track for a full recovery.\n",
        "Patient: Thank you, doctor. I appreciate it.\n",
        "Physician: You're very welcome, Ms. Jones. Take care, and don't hesitate to reach out if you need anything.\n",
        "\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F02TE249vff_"
      },
      "source": [
        "## Step 11: Run the Machine\n",
        "\n",
        "Run this cell to see all the results in one place!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jw-wgLAyvff_",
        "outputId": "22e808a4-d94b-4580-8809-93d00cd2fb75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing Medical NLP Pipeline...\n",
            "Initializing modules...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/spacy/util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.8.0) was trained with spaCy v3.8.0 and may not be 100% compatible with the current version (3.7.5). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
            "  warnings.warn(warn_msg)\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading GenAI SOAP Model (google/flan-t5-base)...\n",
            "\n",
            "Processing Transcript...\n",
            "--------------------------------------------------\n",
            "                MEDICAL REPORT OUTPUT\n",
            "--------------------------------------------------\n",
            "\n",
            "--- 1. SAFETY & VALIDATION ---\n",
            "Confidence Score: 1.0\n",
            "No clinical contradictions detected.\n",
            "\n",
            "--- 2. STRUCTURED SUMMARY ---\n",
            "{\n",
            "  \"Patient_Name\": \"Janet Jones\",\n",
            "  \"Symptoms\": [\n",
            "    \"Difficulty Concentrating\",\n",
            "    \"Neck And Back Pain\",\n",
            "    \"No tenderness\",\n",
            "    \"Anxiety\",\n",
            "    \"Discomfort\",\n",
            "    \"Stiffness\",\n",
            "    \"Nervous\"\n",
            "  ],\n",
            "  \"Diagnosis\": \"Whiplash Injury\",\n",
            "  \"Treatment\": [\n",
            "    \"Painkillers\",\n",
            "    \"Physical Examination\"\n",
            "  ],\n",
            "  \"Current_Status\": null,\n",
            "  \"Prognosis\": \"Full Recovery, No Signs Of Long-Term Damage\"\n",
            "}\n",
            "\n",
            "--- 3. PSYCHOLOGICAL PROFILE ---\n",
            "{\n",
            "  \"Sentiment\": \"Anxious\",\n",
            "  \"Intent\": [\n",
            "    \"Reporting symptoms\"\n",
            "  ],\n",
            "  \"Confidence\": 0.9939401149749756\n",
            "}\n",
            "\n",
            "--- 4. SOAP NOTE (Rule-Based) ---\n",
            "{\n",
            "  \"subjective\": {\n",
            "    \"Chief_Complaint\": \"Discomfort; Neck And Back Pain; Stiffness; Discomfort; Anxiety; Difficulty Concentrating; Nervous\",\n",
            "    \"History_of_Present_Illness\": \"Received Painkillers\"\n",
            "  },\n",
            "  \"objective\": {\n",
            "    \"Physical_Exam\": \"No tenderness\",\n",
            "    \"Observations\": \"None reported\"\n",
            "  },\n",
            "  \"assessment\": {\n",
            "    \"Diagnosis\": \"Whiplash Injury\",\n",
            "    \"Severity\": \"None reported\"\n",
            "  },\n",
            "  \"plan\": {\n",
            "    \"Treatment\": \"Physical Examination; Physical Examination\",\n",
            "    \"Follow-Up\": \"Full Recovery; No Signs Of Long-Term Damage; Full Recovery\"\n",
            "  }\n",
            "}\n",
            "\n",
            "--- 5.AI Model Summary ---\n",
            "Patient: I'm doing better, but I still have some discomfort now and then. I was in a car accident last September. I was driving from Cheadle Hulme to Manchester when I had to stop in traffic. Out of nowhere, another car hit me from behind, which pushed my car into the one in front.\n",
            "\n",
            "[File Saved] Full detailed JSON report saved to 'output_report.json'\n"
          ]
        }
      ],
      "source": [
        "def run_demo():\n",
        "    print(\"Initializing Medical NLP Pipeline...\")\n",
        "    pipeline = MedicalPipeline()\n",
        "\n",
        "    print(\"\\nProcessing Transcript...\")\n",
        "    result = pipeline.process_conversation(TRANSCRIPT)\n",
        "\n",
        "    print(\"-\" * 50)\n",
        "    print(\"                MEDICAL REPORT OUTPUT\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # 1. SAFETY & VALIDATION\n",
        "    print(\"\\n--- 1. SAFETY & VALIDATION ---\")\n",
        "    print(f\"Confidence Score: {result.validation.overall_confidence}\")\n",
        "    if result.validation.contradictions:\n",
        "        print(\"CONTRADICTIONS FOUND:\")\n",
        "        for c in result.validation.contradictions:\n",
        "            print(f\"  - {c}\")\n",
        "    else:\n",
        "        print(\"No clinical contradictions detected.\")\n",
        "\n",
        "    # 2. Structured Summary\n",
        "    print(\"\\n--- 2. STRUCTURED SUMMARY ---\")\n",
        "    # Reformat the summary into the desired output structure\n",
        "    custom_formatted_output = {\n",
        "        \"Patient_Name\": result.summary.patient_name,\n",
        "        \"Symptoms\": result.summary.symptoms,\n",
        "        \"Diagnosis\": result.summary.diagnosis,\n",
        "        \"Treatment\": result.summary.treatment,\n",
        "        \"Current_Status\": result.summary.current_status,\n",
        "        \"Prognosis\": result.summary.prognosis\n",
        "    }\n",
        "    print(json.dumps(custom_formatted_output, indent=2))\n",
        "\n",
        "    # 3. PSYCHOLOGICAL PROFILE\n",
        "    print(\"\\n--- 3. PSYCHOLOGICAL PROFILE ---\")\n",
        "    psychological_profile = {\n",
        "        \"Sentiment\": result.sentiment_analysis.patient_sentiment,\n",
        "        \"Intent\": result.sentiment_analysis.intent,\n",
        "        \"Confidence\": result.sentiment_analysis.confidence\n",
        "    }\n",
        "    print(json.dumps(psychological_profile, indent=2))\n",
        "\n",
        "    # 4. SOAP Note (Bonus Model)\n",
        "    print(\"\\n--- 4. SOAP NOTE (Rule-Based) ---\")\n",
        "    print(json.dumps(result.soap_note.model_dump(), indent=2))\n",
        "\n",
        "    # 5.AI Model Summary\n",
        "    print(\"\\n--- 5.AI Model Summary ---\")\n",
        "    print(result.ai_generated_soap if result.ai_generated_soap else \"No AI/Generation Failed\")\n",
        "\n",
        "    # Save to file\n",
        "    with open(\"output_report.json\", \"w\") as f:\n",
        "        f.write(result.model_dump_json(indent=2))\n",
        "    print(\"\\n[File Saved] Full detailed JSON report saved to 'output_report.json'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_demo()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Regarding Answers to the questions asked in the Assignment is submitted in answers.md in the same directory.\n",
        "\n",
        "Check : https://github.com/diya-matani/Physician-Notetaker/blob/main/Answers.md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Github Link: https://github.com/diya-matani/Physician-Notetaker "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
